












<!doctype html>

<meta name="viewport" content="width=device-width, initial-scale=1" />

<link rel="stylesheet" href="/_static/spectre.css">
<link rel="stylesheet" href="/_static/pygments.css">
<link rel="stylesheet" href="/_static/style.css">

<link rel="alternate" type="application/atom+xml" title="Atom feed" href="/_feed/index.xml" />

<link rel="icon" href="/_static/xo-system-icon.svg">
<link rel="apple-touch-icon" href="/_static/xo-system-icon.svg">







<title>Process​Thread​Pool​Executor: when I‍/‍O becomes CPU-bound - death and gravity</title>
<meta name="description" content="...in which we build a hybrid concurrent.futures executor that runs I‍/‍O bound tasks on all available CPUs, thus evading the limitations imposed by the dreaded global interpreter lock on the humble ThreadPoolExecutor." />


<meta property="og:title" content="Process​Thread​Pool​Executor: when I‍/‍O becomes CPU-bound">
<meta property="og:site_name" content="death and gravity">
<meta property="og:type" content="article">
<meta property="og:url" content="https://death.andgravity.com/ptpe">
<meta property="og:description" content="...in which we build a hybrid concurrent.futures executor that runs I‍/‍O bound tasks on all available CPUs, thus evading the limitations imposed by the dreaded global interpreter lock on the humble ThreadPoolExecutor.">



<script>
/* https://css-tricks.com/the-trick-to-viewport-units-on-mobile/ */
function set_vh() {
    let vh = window.innerHeight * 0.01;
    document.documentElement.style.setProperty('--vh', `${vh}px`);
}
/* we do it once, now, *and* on every resize */
set_vh();
window.addEventListener('resize', set_vh);
</script>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4RY2QR580X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "G-4RY2QR580X");
</script>



<div class="main container grid-lg">


<header>
<nav>
<ul class="breadcrumb">

<li class="breadcrumb-item">
    <a href="/">death and gravity</a>
</li>

</ul>
</nav>

<h1 class="heading-noindex">Process​Thread​Pool​Executor: when I‍/‍O becomes CPU-bound</h1>

<p class="text-gray text-nowrap">



<small>
<span class="tooltip" data-tooltip="published on 2025-04-18">April 2025</span>
∙ 16 minute read
∙
</small><span class="share-icons">
<a
    class="share-icon pycoders"
    href="https://pycoders.com/submissions"
    target="_blank"
>PyCoder's Weekly</a>
<a
    class="share-icon hacker-news"
    href="https://news.ycombinator.%63%6f%6d/submitlink?u=https%3A//death.andgravity.com/ptpe&t=Process%E2%80%8BThread%E2%80%8BPool%E2%80%8BExecutor%3A%20when%20I%E2%80%8D/%E2%80%8DO%20becomes%20CPU-bound"
>HN</a>
<a
    class="share-icon reddit"
    href="https://www.reddit.%63%6f%6d/%73%75%62%6d%69%74?url=https%3A//death.andgravity.com/ptpe&title=Process%E2%80%8BThread%E2%80%8BPool%E2%80%8BExecutor%3A%20when%20I%E2%80%8D/%E2%80%8DO%20becomes%20CPU-bound"
>Reddit</a>
<a
    class="share-icon linkedin"
    href="https://www.linkedin.%63%6f%6d/sharing/share-offsite/?url=https%3A//death.andgravity.com/ptpe"
>linkedin</a>
<a
    class="share-icon twitter"
    href="https://twitter.%63%6f%6d/%73%68%61%72%65?text=Process%E2%80%8BThread%E2%80%8BPool%E2%80%8BExecutor%3A%20when%20I%E2%80%8D/%E2%80%8DO%20becomes%20CPU-bound&url=https%3A//death.andgravity.com/ptpe&via=_andgravity"
>Twitter</a>
</span>


</p>






</header>


<main class="content columns">
<div class="column col-sm-12 col-md-10 col-8">

<p>So, you're doing some I‍/‍O bound stuff, in parallel.</p>
<p>Maybe you're scraping some websites – a <em>lot</em> of websites.</p>
<p>Maybe you're updating or deleting millions of DynamoDB items.</p>
<p>You've got your <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor">ThreadPoolExecutor</a>,
you've increased the number of threads and tuned connection limits...
but after some point, <strong>it's just not getting any faster</strong>.
You look at your Python process,
and you see CPU utilization hovers above 100%.</p>
<p>You <em>could</em> split the work into batches
and have a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor">ProcessPoolExecutor</a>
run your original code in separate processes.
But that requires yet more code, and a bunch of changes, which is no fun.
And maybe your input is not that easy to split into batches.</p>
<p>If only we had an executor that
<strong>worked seamlessly across processes and threads</strong>.</p>
<p>Well, you're in luck, since that's exactly what we're building today!</p>
<p>And even better, in a couple years you won't even need it anymore.</p>
<section class="toc">
<ul>
<li><a href="#establishing-a-baseline">Establishing a baseline</a>
<ul>
<li><a href="#threads">Threads</a></li>
<li><a href="#problem-cpu-becomes-a-bottleneck">Problem: CPU becomes a bottleneck</a></li>
<li><a href="#processes">Processes?</a></li>
<li><a href="#problem-more-processes-more-memory">Problem: more processes, more memory</a></li>
</ul>
</li>
<li><a href="#why-not-both">Why not both?</a>
<ul>
<li><a href="#a-minimal-plausible-solution">A minimal plausible solution</a></li>
<li><a href="#getting-results">Getting results</a></li>
<li><a href="#fine-we-ll-make-our-own-futures">Fine, we'll make our own futures</a></li>
<li><a href="#death-becomes-a-problem">Death becomes a problem</a></li>
</ul>
</li>
<li><a href="#bonus-free-threading">Bonus: free threading</a></li>
</ul>
</section>
<h2 id="establishing-a-baseline">Establishing a baseline<span class="headerlink">&nbsp;<a href="#establishing-a-baseline" title="permalink">#</a></span></h2>
<p>To measure things,
we'll use a mock that pretends to do <a class="external" href="https://en.wikipedia.org/wiki/I/O_bound">mostly I‍/‍O</a>,
with a sprinkling of <a class="external" href="https://en.wikipedia.org/wiki/CPU-bound">CPU-bound</a> work thrown in
– a stand-in for something like a database connection,
a Requests <a class="external" href="https://requests.readthedocs.io/en/latest/user/advanced/#session-objects">session</a>, or a <a class="external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client">DynamoDB client</a>.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Client</span><span class="p">:</span>
    <span class="n">io_time</span> <span class="o">=</span> <span class="mf">0.02</span>
    <span class="n">cpu_time</span> <span class="o">=</span> <span class="mf">0.0008</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="p">):</span>
        <span class="c1"># simulate I/O</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">io_time</span><span class="p">)</span>

        <span class="c1"># simulate CPU-bound work</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="k">while</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_time</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span> <span class="n">i</span> <span class="o">**</span> <span class="n">i</span>

        <span class="k">return</span> <span class="n">arg</span>
</code></pre></div>

<p>We <a class="external" href="https://docs.python.org/3/library/time.html#time.sleep">sleep()</a> for the I‍/‍O,
and do some math in a loop for the CPU stuff;
it doesn't matter exactly how long each takes,
as long I‍/‍O time dominates.</p>
<p><a id="connection-pool"></a>
Real multi-threaded clients are usually backed by a shared connection pool,
which allows for connection reuse
(so you don't pay the cost of a new connection on each request)
and multiplexing
(so you can use the same connection for multiple concurrent requests,
possible with protocols like HTTP/2 or newer).
We could simulate this with a <a class="external" href="https://docs.python.org/3/library/threading.html#semaphore-objects">semaphore</a>,
but limiting connections is not relevant here
– we're assuming the connection pool is effectively unbounded.</p>
<p>Since we'll use our client from multiple processes,
we write an initializer function
to set up a global, per-process client instance
(remember, we want to share potential connection pools between threads);
we can then pass the initializer
to the <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor">executor</a> constructor,
along with any arguments we want to pass to the client.
Similarly, we do the work through a function that uses this global client.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="c1"># this code runs in each worker process</span>

<span class="n">client</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">init_client</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">client</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">do_stuff</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">client</span><span class="o">.</span><span class="n">method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>

<p>Finally, we make a simple timing context manager:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">timer</span><span class="p">():</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">yield</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;elapsed: </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s2">1.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>...and put everything together in a function
that measures how long it takes
to do a bunch of work
using a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html">concurrent.futures</a> executor:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">benchmark</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">timer</span><span class="o">=</span><span class="n">timer</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">executor</span><span class="p">:</span>
        <span class="c1"># make sure all the workers are started,</span>
        <span class="c1"># so we don&#39;t measure their startup time</span>
        <span class="nb">list</span><span class="p">(</span><span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">200</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">timer</span><span class="p">():</span>
            <span class="n">values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">do_stuff</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">chunksize</span><span class="p">))</span>

        <span class="k">assert</span> <span class="n">values</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="n">values</span>
</code></pre></div>

<h3 id="threads">Threads<span class="headerlink">&nbsp;<a href="#threads" title="permalink">#</a></span></h3>
<!-- FIXME: note about python version and computer used -->
<p>So, a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor">ThreadPoolExecutor</a> should suffice here,
since we're mostly doing I‍/‍O, right?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">bench</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init_client</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="go">elapsed: 24.693</span>
</code></pre></div>
<p>More threads!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
<span class="go">elapsed: 12.405</span>
</code></pre></div>
<p>Twice the threads, twice as fast. More!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">))</span>
<span class="go">elapsed: 8.718</span>
</code></pre></div>
<p>Good, it's still scaling linearly. MORE!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">))</span>
<span class="go">elapsed: 8.638</span>
</code></pre></div>
<p><img class="img-responsive" src="/_file/ptpe/confused.jpg" alt="confused cat with question marks around its head" /></p>
<p>...more?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>
<span class="go">elapsed: 8.458</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">60</span><span class="p">))</span>
<span class="go">elapsed: 8.430</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">70</span><span class="p">))</span>
<span class="go">elapsed: 8.428</span>
</code></pre></div>
<!-- ![confused cat with raised eyebrow collage](attachment:confused2.jpg) -->
<!-- !["what in tarnation" shiba inu dog wearing a cowboy hat](attachment:tarnation.jpg) -->
<!-- !["what in tarnation?" cat wearing a cowboy hat](attachment:tarnation2.jpg) -->
<!-- ![confused cat snarling](attachment:wtf.jpg) -->
<!-- ![slightly concerned cat looking at reader](attachment:concern.jpg) -->
<p><img class="img-responsive" src="/_file/ptpe/confused3.jpg" alt="squinting confused cat" /></p>
<!-- ## Problem: CPU becomes a bottleneck when you do enough I&zwj;/&zwj;O -->
<h3 id="problem-cpu-becomes-a-bottleneck">Problem: CPU becomes a bottleneck<span class="headerlink">&nbsp;<a href="#problem-cpu-becomes-a-bottleneck" title="permalink">#</a></span></h3>
<p>It's time we take a closer look at what our process is doing.
I'd normally use the <a class="external" href="https://linux.die.net/man/1/top">top</a> command for this,
but since the flags and output vary with the operating system,
we'll implement our own using the excellent <a class="external" href="https://psutil.readthedocs.io/">psutil</a> library.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">top</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print information about current and child processes.</span>

<span class="sd">    RES is the resident set size. USS is the unique set size.</span>
<span class="sd">    %CPU is the CPU utilization. nTH is the number of threads.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">process</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span>
    <span class="n">processes</span> <span class="o">=</span> <span class="p">[</span><span class="n">process</span><span class="p">]</span> <span class="o">+</span> <span class="n">process</span><span class="o">.</span><span class="n">children</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">cpu_percent</span><span class="p">()</span>

    <span class="k">yield</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;PID&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;RES&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;USS&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;%CPU&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;nTH&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">memory_full_info</span><span class="p">()</span>
        <span class="k">except</span> <span class="n">psutil</span><span class="o">.</span><span class="n">AccessDenied</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span>
        <span class="n">rss</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>
        <span class="n">uss</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;uss&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>
        <span class="n">cpu</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cpu_percent</span><span class="p">()</span>
        <span class="n">nth</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">num_threads</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">pid</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">rss</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2">m </span><span class="si">{</span><span class="n">uss</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2">m </span><span class="si">{</span><span class="n">cpu</span><span class="si">:</span><span class="s2">7.1f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">nth</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>And because it's a context manager, we can use it as a timer:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">init_client</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  51395   35.2m   28.5m    38.7      11</span>
</code></pre></div>
<p>So, what happens if we increase the number of threads?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   16.8m   13.2m    70.7      21</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   17.0m   13.4m    99.1      31</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   17.3m   13.7m   100.9      41</span>
</code></pre></div>
<p>With more threads, the compute part of our I‍/‍O bound workload increases,
eventually becoming high enough to saturate one CPU
– and due to the <a class="external" href="https://docs.python.org/3/glossary.html#term-global-interpreter-lock">global interpreter lock</a>,
<em>one CPU is all we can use</em>, regardless of the number of threads.<sup class="footnote-ref" id="fnref-1"><a href="#fn-1">1</a></sup></p>
<h3 id="processes">Processes?<span class="headerlink">&nbsp;<a href="#processes" title="permalink">#</a></span></h3>
<p>I know, let's use a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor">ProcessPoolExecutor</a> instead!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 12.374</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 8.330</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 6.273</span>
</code></pre></div>
<p>Hmmm... I guess it <em>is</em> a little bit better.</p>
<p>More? More!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 4.751</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 3.785</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 3.824</span>
</code></pre></div>
<p>OK, it's better, but with diminishing returns
– there's no improvement after 80 processes,
and even then, it's only <strong>2.2x</strong> faster than the best time with threads,
when, in theory, it should be able to make full use of all 4 CPUs.</p>
<p>Also, we're not making best use of
<a class="anchor" href="#connection-pool">connection pools</a>
(since we now have 80 of them, one per process),
nor multiplexing
(since we now have 80 connections, one per pool).</p>
<h3 id="problem-more-processes-more-memory">Problem: more processes, more memory<span class="headerlink">&nbsp;<a href="#problem-more-processes-more-memory" title="permalink">#</a></span></h3>
<p>But it gets worse!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">   2479   21.2m   15.4m    15.0       3</span>
<span class="go">   2480   11.2m    6.3m     0.0       1</span>
<span class="go">   2481   13.8m    8.5m     3.4       1</span>
<span class="go">  ... 78 more lines ...</span>
<span class="go">   2560   13.8m    8.5m     4.4       1</span>
</code></pre></div>
<p>13.8 MiB * 80 ~= 1 GiB ... that is <em>a lot</em> of memory.</p>
<p><strong>Now, there's some nuance to be had here.</strong></p>
<p>First, on most operating systems that have virtual memory,
<a class="external" href="https://en.wikipedia.org/wiki/Code_segment">code segment</a> pages are shared between processes
– there's no point in having 80 copies
of libc or the Python interpreter in memory.</p>
<p>The <a class="external" href="https://en.wikipedia.org/wiki/Unique_set_size">unique set size</a> is probably a better measurement
than the <a class="external" href="https://en.wikipedia.org/wiki/Resident_set_size">resident set size</a>,
since it excludes memory shared between processes.<sup class="footnote-ref" id="fnref-2"><a href="#fn-2">2</a></sup>
So, for the macOS output above,<sup class="footnote-ref" id="fnref-3"><a href="#fn-3">3</a></sup>
the actual usage is more like 8.5 MiB * 80 = 680 MiB.</p>
<p>Second, if you use the <em>fork</em> or <em>forkserver</em> <a class="external" href="https://docs.python.org/3.14/library/multiprocessing.html#contexts-and-start-methods">start methods</a>,
processes also share memory allocated before the <a class="external" href="https://en.wikipedia.org/wiki/Fork_(system_call)">fork()</a> via <a class="external" href="https://en.wikipedia.org/wiki/Copy-on-write#In_virtual_memory_management">copy-on-write</a>;
for Python, this includes module code and variables.
On Linux, the actual usage is 1.7 MiB * 80 = 136 MiB:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go"> 329801   17.0m    6.6m     5.1       3</span>
<span class="go"> 329802   13.3m    1.6m     2.1       1</span>
<span class="go">  ... 78 more lines ...</span>
<span class="go"> 329881   13.3m    1.7m     2.0       1</span>
</code></pre></div>
<p>However, it's important to note that's just a lower bound;
memory allocated after <a class="external" href="https://en.wikipedia.org/wiki/Fork_(system_call)">fork()</a> is not shared,
and most real work will unavoidably allocate more memory.</p>



<div class="panel inline-panel" >
    <div class="panel-header text-large">
        Liking this so far? Here&#39;s another article you might like:
    </div>
    <div class="panel-body">
        <p><a href="/same-arguments">
            When to use classes in Python? When your functions take the same arguments
        </a>
    </div>
</div>
<h2 id="why-not-both">Why not both?<span class="headerlink">&nbsp;<a href="#why-not-both" title="permalink">#</a></span></h2>
<p>One reasonable way of dealing with this
would be to split the input into batches,
one per CPU, and pass them to a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor">ProcessPoolExecutor</a>,
which in turn runs the batch items using a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor">ThreadPoolExecutor</a>.<sup class="footnote-ref" id="fnref-4"><a href="#fn-4">4</a></sup></p>
<p>But that would mean we need to change our code, and that's no fun.</p>
<p>If only we had an executor that
<strong>worked seamlessly across processes and threads</strong>.</p>
<h3 id="a-minimal-plausible-solution">A minimal plausible solution<span class="headerlink">&nbsp;<a href="#a-minimal-plausible-solution" title="permalink">#</a></span></h3>
<p>In keeping with what has
<a class="internal" href="/pwned#a-minimal-plausible-solution">become</a>
<a class="internal" href="/lru-cache#a-minimal-plausible-solution">tradition</a>
by now,
we'll take an iterative, <a class="external" href="https://hintjens.gitbooks.io/scalable-c/content/chapter1.html#problem-what-do-we-do-next">problem-solution</a> approach;
since we're <em>not sure what to do yet</em>,
we start with <a class="external" href="https://wiki.c2.com/?DoTheSimplestThingThatCouldPossiblyWork">the simplest thing that could possibly work</a>.</p>
<p>We know we want a process pool executor
that starts one thread pool executor per process,
so let's deal with that first.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ProcessPoolExecutor</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">initializer</span><span class="o">=</span><span class="n">_init_process</span><span class="p">,</span>
            <span class="n">initargs</span><span class="o">=</span><span class="p">(</span><span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<p>By subclassing ProcessPoolExecutor,
we get the <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map">map()</a> implementation for free,
since the original is implemented in terms of <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.submit">submit()</a>.<sup class="footnote-ref" id="fnref-5"><a href="#fn-5">5</a></sup>
By going with the default <code>max_workers</code>,
we get one process per CPU (which is what we want);
we can add more arguments later if needed.</p>
<p>In a custom process initializer,
we set up a global thread pool executor,<sup class="footnote-ref" id="fnref-6"><a href="#fn-6">6</a></sup>
and then call the process initializer provided by the user:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="c1"># this code runs in each worker process</span>

<span class="n">_executor</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_init_process</span><span class="p">(</span><span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_executor</span>

    <span class="n">_executor</span> <span class="o">=</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_threads</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">initializer</span><span class="p">:</span>
        <span class="n">initializer</span><span class="p">(</span><span class="o">*</span><span class="n">initargs</span><span class="p">)</span>
</code></pre></div>

<p>Likewise, <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.submit">submit()</a> passes the work along
to the thread pool executor:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ProcessPoolExecutor</span><span class="p">):</span>
    <span class="c1"># ...</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">submit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_submit</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="c1"># this code runs in each worker process</span>
<span class="c1"># ...</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
</code></pre></div>

<p>OK, that looks good enough;
let's use it and see if it works:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_do_stuff</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;doing: </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">n</span> <span class="o">**</span> <span class="mi">2</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">ProcessThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_do_stuff</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])))</span>
</code></pre></div>

<div class="highlight code-container"><pre class="code" data-lang="Bash Session"><span></span><code><span class="gp"> $ </span>python<span class="w"> </span>ptpe.py
<span class="go">doing: 0</span>
<span class="go">doing: 1</span>
<span class="go">doing: 2</span>
<span class="go">[0, 1, 4]</span>
</code></pre></div>
<p>Wait, we got it on the first try?!</p>
<p>Let's measure that:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">bench</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ptpe</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="go">elapsed: 6.161</span>
</code></pre></div>
<p>Hmmm... that's unexpectedly slow... almost as if:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="go">elapsed: 6.067</span>
</code></pre></div>
<p>Ah, because <code>_submit()</code> waits for the <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future.result">result()</a>
in the main thread of the worker process,
this is just a ProcessPoolExecutor with extra steps.</p>
<hr />
<p>But what if we send back the <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#future-objects">future</a> object instead?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">submit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_submit</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
</code></pre></div>

<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

<p>Alas:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="go">$ python ptpe.py</span>
<span class="go">doing: 0</span>
<span class="go">doing: 1</span>
<span class="go">doing: 2</span>
<span class="go">concurrent.futures.process._RemoteTraceback:</span>
<span class="go">&quot;&quot;&quot;</span>
<span class="gt">Traceback (most recent call last):</span>
  File <span class="nb">&quot;concurrent/futures/process.py&quot;</span>, line <span class="m">210</span>, in <span class="n">_sendback_result</span>
<span class="w">    </span><span class="n">result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">_ResultItem</span><span class="p">(</span><span class="n">work_id</span><span class="p">,</span> <span class="n">result</span><span class="o">=</span><span class="n">result</span><span class="p">,</span>
  File <span class="nb">&quot;multiprocessing/queues.py&quot;</span>, line <span class="m">391</span>, in <span class="n">put</span>
<span class="w">    </span><span class="n">obj</span> <span class="o">=</span> <span class="n">_ForkingPickler</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
  File <span class="nb">&quot;multiprocessing/reduction.py&quot;</span>, line <span class="m">51</span>, in <span class="n">dumps</span>
<span class="w">    </span><span class="bp">cls</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="n">protocol</span><span class="p">)</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
<span class="gr">TypeError</span>: <span class="n">cannot pickle &#39;_thread.RLock&#39; object</span>
<span class="x">&quot;&quot;&quot;</span>

<span class="gt">The above exception was the direct cause of the following exception:</span>

<span class="gt">Traceback (most recent call last):</span>
  File <span class="nb">&quot;ptpe.py&quot;</span>, line <span class="m">42</span>, in <span class="n">&lt;module&gt;</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_do_stuff</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])))</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">TypeError</span>: <span class="n">cannot pickle &#39;_thread.RLock&#39; object</span>
</code></pre></div>
<p>The immediate cause of the error is that
the future
<a class="external" href="https://github.com/python/cpython/blob/3.13/Lib/concurrent/futures/_base.py#L330">has a condition</a>
that <a class="external" href="https://github.com/python/cpython/blob/3.13/Lib/threading.py#L284">has a lock</a>
that can't be <a class="external" href="https://docs.python.org/3/library/pickle.html#object.__reduce__">pickled</a>,
because <a class="external" href="https://docs.python.org/3/library/threading.html">threading</a> locks only make sense within the same process.</p>
<p>The deeper cause is that the <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#future-objects">future</a> is not just data,
but encapsulates state owned by the thread pool executor,
and <a class="external" href="https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes">sharing state between processes</a> requires extra work.</p>
<p>It may not seem like it, but this is a partial success:
the work happens,
we just can't get the results back.
Not surprising, to be honest, it couldn't have been <em>that</em> easy.</p>
<h3 id="getting-results">Getting results<span class="headerlink">&nbsp;<a href="#getting-results" title="permalink">#</a></span></h3>
<p>If you look carefully at the traceback,
you'll find a hint of how <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor">ProcessPoolExecutor</a>
gets its own results back from workers
– a queue;
the <a class="external" href="https://github.com/python/cpython/blob/3.13/Lib/concurrent/futures/process.py">module docstring</a> even has a neat data-flow diagram:</p>
<p><a name="data-flow"></a></p>
<pre class="code code-container"><code>|======================= In-process =====================|== Out-of-process ==|

+----------+     +----------+       +--------+     +-----------+    +---------+
|          |  =&gt; | Work Ids |       |        |     | Call Q    |    | Process |
|          |     +----------+       |        |     +-----------+    |  Pool   |
|          |     | ...      |       |        |     | ...       |    +---------+
|          |     | 6        |    =&gt; |        |  =&gt; | 5, call() | =&gt; |         |
|          |     | 7        |       |        |     | ...       |    |         |
| Process  |     | ...      |       | Local  |     +-----------+    | Process |
|  Pool    |     +----------+       | Worker |                      |  #1..n  |
| Executor |                        | Thread |                      |         |
|          |     +----------- +     |        |     +-----------+    |         |
|          | &lt;=&gt; | Work Items | &lt;=&gt; |        | &lt;=  | Result Q  | &lt;= |         |
|          |     +------------+     |        |     +-----------+    |         |
|          |     | 6: call()  |     |        |     | ...       |    |         |
|          |     |    future  |     |        |     | 4, result |    |         |
|          |     | ...        |     |        |     | 3, except |    |         |
+----------+     +------------+     +--------+     +-----------+    +---------+
</code></pre>
<p>Now, we could probably use the same queue somehow,
but it would involve touching a lot of (private) internals.<sup class="footnote-ref" id="fnref-7"><a href="#fn-7">7</a></sup>
Instead, let's use a separate queue:</p>
<!--
this is one of the rare cases where
we have to use [double underscores],
otherwise we'll clobber the original `_result_queue` attribute.
-->
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">initializer</span><span class="o">=</span><span class="n">_init_process</span><span class="p">,</span>
            <span class="n">initargs</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="p">,</span> <span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<p>On the worker side, we make it globally accessible:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="c1"># this code runs in each worker process</span>

<span class="n">_executor</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">_result_queue</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_init_process</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_executor</span><span class="p">,</span> <span class="n">_result_queue</span>

    <span class="n">_executor</span> <span class="o">=</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_threads</span><span class="p">)</span>
    <span class="n">_result_queue</span> <span class="o">=</span> <span class="n">queue</span>

    <span class="k">if</span> <span class="n">initializer</span><span class="p">:</span>
        <span class="n">initializer</span><span class="p">(</span><span class="o">*</span><span class="n">initargs</span><span class="p">)</span>
</code></pre></div>

<p>...so we can use it from a task callback registered by <code>_submit()</code>:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">task</span><span class="o">.</span><span class="n">add_done_callback</span><span class="p">(</span><span class="n">_put_result</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_put_result</span><span class="p">(</span><span class="n">task</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">exception</span> <span class="o">:=</span> <span class="n">task</span><span class="o">.</span><span class="n">exception</span><span class="p">():</span>
        <span class="n">_result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="kc">False</span><span class="p">,</span> <span class="n">exception</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="kc">True</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
</code></pre></div>

<p>Back in the main process, we handle the results in a thread:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="c1"># ...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__result_handler</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__handle_results</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__result_handler</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</code></pre></div>

<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__handle_results</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">ok</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;ok&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">ok</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;error&#39;</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Finally, to stop the handler,
we use None as a <a class="internal" href="/sentinels#what-s-a-sentinel-and-why-do-i-need-one">sentinel</a>
on executor shutdown:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="n">wait</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">wait</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__result_handler</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div>

<p>Let's see if it works:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="go">$ python ptpe.py</span>
<span class="go">doing: 0</span>
<span class="go">ok: [0]</span>
<span class="go">doing: 1</span>
<span class="go">ok: [1]</span>
<span class="go">doing: 2</span>
<span class="go">ok: [4]</span>
<span class="gt">Traceback (most recent call last):</span>
  File <span class="nb">&quot;concurrent/futures/_base.py&quot;</span>, line <span class="m">317</span>, in <span class="n">_result_or_cancel</span>
<span class="w">    </span><span class="k">return</span> <span class="n">fut</span><span class="o">.</span><span class="n">result</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span>
<span class="gr">AttributeError</span>: <span class="n">&#39;NoneType&#39; object has no attribute &#39;result&#39;</span>

<span class="gt">During handling of the above exception, another exception occurred:</span>

<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">AttributeError</span>: <span class="n">&#39;NoneType&#39; object has no attribute &#39;cancel&#39;</span>
</code></pre></div>
<p>Yay, the results are making it to the handler!</p>
<p>The error happens because instead of returning a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#future-objects">Future</a>,
our <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.submit">submit()</a> returns the result of <code>_submit()</code>, which is always None.</p>
<h3 id="fine-we-ll-make-our-own-futures">Fine, we'll make our own futures<span class="headerlink">&nbsp;<a href="#fine-we-ll-make-our-own-futures" title="permalink">#</a></span></h3>
<p>But <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.submit">submit()</a> <em>must</em> return a future, so we make our own:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="c1"># ...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># ...</span>
</code></pre></div>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">submit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">outer</span> <span class="o">=</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">Future</span><span class="p">()</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="nb">id</span><span class="p">(</span><span class="n">outer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">outer</span>

        <span class="n">outer</span><span class="o">.</span><span class="n">set_running_or_notify_cancel</span><span class="p">()</span>
        <span class="n">inner</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_submit</span><span class="p">,</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outer</span>
</code></pre></div>

<p>In order to map results to their futures,
we can use a unique identifier;
the <a class="external" href="https://docs.python.org/3/library/functions.html#id">id()</a> of the outer future should do,
since it is unique for the object's lifetime.</p>
<p>We pass the id to <code>_submit()</code>,
then to <code>_put_result()</code> as an attribute on the future,
and finally back in the queue with the result:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">task</span><span class="o">.</span><span class="n">task_id</span> <span class="o">=</span> <span class="n">task_id</span>
    <span class="n">task</span><span class="o">.</span><span class="n">add_done_callback</span><span class="p">(</span><span class="n">_put_result</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_put_result</span><span class="p">(</span><span class="n">task</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">exception</span> <span class="o">:=</span> <span class="n">task</span><span class="o">.</span><span class="n">exception</span><span class="p">():</span>
        <span class="n">_result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">task</span><span class="o">.</span><span class="n">task_id</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">exception</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">task</span><span class="o">.</span><span class="n">task_id</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
</code></pre></div>

<p>Back in the result handler,
we find the maching future,
and set the result accordingly:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__handle_results</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">ok</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">outer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ok</span><span class="p">:</span>
                <span class="n">outer</span><span class="o">.</span><span class="n">set_result</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outer</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div>

<p>And it works:</p>
<div class="highlight code-container"><pre class="code" data-lang="Bash Session"><span></span><code><span class="gp">$ </span>python<span class="w"> </span>ptpe.py
<span class="go">doing: 0</span>
<span class="go">doing: 1</span>
<span class="go">doing: 2</span>
<span class="go">[0, 1, 4]</span>
</code></pre></div>
<p>I mean, it <em>really</em> works:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 6.220</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 3.397</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 2.575</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 2.664</span>
</code></pre></div>
<p><strong>3.3x</strong> is not <em>quite</em> the 4 CPUs my laptop has,
but it's pretty close,
and much better than the 2.2x we got from processes alone.</p>
<h3 id="death-becomes-a-problem">Death becomes a problem<span class="headerlink">&nbsp;<a href="#death-becomes-a-problem" title="permalink">#</a></span></h3>
<p>I wonder what happens when a worker process dies.</p>
<p>For example, the initializer can fail:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">executor</span> <span class="o">=</span> <span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="n">initializer</span><span class="o">=</span><span class="nb">divmod</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
<span class="go">Exception in initializer:</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">ZeroDivisionError</span>: <span class="n">integer division or modulo by zero</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">concurrent.futures.process.BrokenProcessPool</span>: <span class="n">A process in the process pool was terminated abruptly while the future was running or pending.</span>
</code></pre></div>
<p>...or a worker can die some time later,
which we can help along with a custom <code>timer</code>:<sup class="footnote-ref" id="fnref-8"><a href="#fn-8">8</a></sup></p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">terminate_child</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">threading</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="n">interval</span><span class="p">,</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">children</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">terminate</span><span class="p">)</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="k">yield</span>
</code></pre></div>

<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">executor</span> <span class="o">=</span> <span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span> <span class="n">timer</span><span class="o">=</span><span class="n">terminate_child</span><span class="p">)</span>
<span class="go">[ one second later ]</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">concurrent.futures.process.BrokenProcessPool</span>: <span class="n">A process in the process pool was terminated abruptly while the future was running or pending.</span>
</code></pre></div>
<p>Now let's see <em>our</em> executor:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">executor</span> <span class="o">=</span> <span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span> <span class="n">timer</span><span class="o">=</span><span class="n">terminate_child</span><span class="p">)</span>
<span class="go">[ one second later ]</span>
<span class="go">[ ... ]</span>
<span class="go">[ still waiting ]</span>
<span class="go">[ ... ]</span>
<span class="go">[ hello? ]</span>
</code></pre></div>
<p>If the dead worker is not around to send back results,
its futures never get completed,
and <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map">map()</a> keeps waiting until the end of time,
when the expected behavior is to detect when this happens, and
fail all pending tasks with <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.process.BrokenProcessPool">BrokenProcessPool</a>.</p>
<hr />
<p>Before we do that, though, let's address a more specific issue.</p>
<p>If <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map">map()</a> hasn't finished submitting tasks when the worker dies,
<code>inner</code> fails with <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.process.BrokenProcessPool">BrokenProcessPool</a>,
which right now we're ignoring entirely.
While we don't need to do anything about it in particular
because it gets covered by handling the general case,
we should still propagate <em>all</em> errors to the <code>outer</code> task anyway.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">submit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># ...</span>
        <span class="n">inner</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_submit</span><span class="p">,</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">inner</span><span class="o">.</span><span class="n">task_id</span> <span class="o">=</span> <span class="n">task_id</span>
        <span class="n">inner</span><span class="o">.</span><span class="n">add_done_callback</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__handle_inner</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outer</span>
</code></pre></div>

<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__handle_inner</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inner</span><span class="p">):</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="n">inner</span><span class="o">.</span><span class="n">task_id</span>
        <span class="k">if</span> <span class="n">exception</span> <span class="o">:=</span> <span class="n">inner</span><span class="o">.</span><span class="n">exception</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">outer</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="n">outer</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">exception</span><span class="p">)</span>
</code></pre></div>

<p>This fixes the case where a worker dies almost instantly:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">executor</span> <span class="o">=</span> <span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span> <span class="n">timer</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">terminate_child</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">concurrent.futures.process.BrokenProcessPool</span>: <span class="n">A process in the process pool was terminated abruptly while the future was running or pending.</span>
</code></pre></div>
<hr />
<p>For the general case,
we need to check if the executor is broken
– but how?
We've already decided we don't want to depend on internals,
so we can't use <a class="external" href="https://github.com/python/cpython/blob/db7ad1c89f8b8f0319ec2f3a20f2f3c226a406ed/Lib/concurrent/futures/process.py#L706">Process​Pool​Executor.​​_broken</a>.
Maybe we can submit a dummy task and see if it fails instead:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__check_broken</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">cancel</span><span class="p">()</span>
        <span class="k">except</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">BrokenExecutor</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;shutdown&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                <span class="k">raise</span>
        <span class="k">return</span> <span class="kc">None</span>
</code></pre></div>

<p>Using it is a bit involved, but not completely awful:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__handle_results</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">last_broken_check</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">now</span> <span class="o">-</span> <span class="n">last_broken_check</span> <span class="o">&gt;=</span> <span class="mf">.1</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">exc</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__check_broken</span><span class="p">():</span>
                    <span class="k">break</span>
                <span class="n">last_broken_check</span> <span class="o">=</span> <span class="n">now</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mf">.1</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">value</span><span class="p">:</span>
                <span class="k">return</span>

            <span class="n">task_id</span><span class="p">,</span> <span class="n">ok</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">if</span> <span class="n">outer</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">ok</span><span class="p">:</span>
                    <span class="n">outer</span><span class="o">.</span><span class="n">set_result</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">outer</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">outer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="o">.</span><span class="n">popitem</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">outer</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">exc</span><span class="p">)</span>
</code></pre></div>

<p>When there's a steady stream of results coming in,
we don't want to check too often,
so we enforce a minimum delay between checks.
When there are <em>no</em> results coming in,
we want to check regularly,
so we use the <a class="external" href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue.get">Queue.get()</a> timeout to avoid waiting forever.
If the check fails, we break out of the loop and fail the pending tasks.
Like so:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">executor</span> <span class="o">=</span> <span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span> <span class="n">timer</span><span class="o">=</span><span class="n">terminate_child</span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">concurrent.futures.process.BrokenProcessPool</span>: <span class="n">A child process terminated abruptly, the process pool is not usable anymore</span>
</code></pre></div>
<p><img class="img-responsive" src="/_file/ptpe/cool.jpg" alt="cool smoking cat wearing denim jacket and sunglasses" /></p>
<hr />
<p>So, yeah, I think we're done.
Here's the final <a class="attachment" href="/_file/ptpe/ptpe.py">executor</a> and <a class="attachment" href="/_file/ptpe/bench.py">benchmark</a> code.</p>
<p>Some features left as an exercise for the reader:</p>
<ul>
<li>providing a ThreadPoolExecutor initializer</li>
<li>using other <a class="external" href="https://docs.python.org/3.14/library/multiprocessing.html#contexts-and-start-methods">start methods</a></li>
<li><a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.shutdown">shutdown()</a>'s <code>cancel_futures</code></li>
</ul>
<p><strong>Learned something new today?</strong> Share this with others, it really helps! <span class="text-large">
<span class="share-icons">
<a
    class="share-icon pycoders color"
    href="https://pycoders.com/submissions"
    target="_blank"
>PyCoder's Weekly</a>
<a
    class="share-icon hacker-news color"
    href="https://news.ycombinator.%63%6f%6d/submitlink?u=https%3A//death.andgravity.com/ptpe&t=Process%E2%80%8BThread%E2%80%8BPool%E2%80%8BExecutor%3A%20when%20I%E2%80%8D/%E2%80%8DO%20becomes%20CPU-bound"
>HN</a>
<a
    class="share-icon reddit color"
    href="https://www.reddit.%63%6f%6d/%73%75%62%6d%69%74?url=https%3A//death.andgravity.com/ptpe&title=Process%E2%80%8BThread%E2%80%8BPool%E2%80%8BExecutor%3A%20when%20I%E2%80%8D/%E2%80%8DO%20becomes%20CPU-bound"
>Reddit</a>
<a
    class="share-icon linkedin color"
    href="https://www.linkedin.%63%6f%6d/sharing/share-offsite/?url=https%3A//death.andgravity.com/ptpe"
>linkedin</a>
<a
    class="share-icon twitter color"
    href="https://twitter.%63%6f%6d/%73%68%61%72%65?text=Process%E2%80%8BThread%E2%80%8BPool%E2%80%8BExecutor%3A%20when%20I%E2%80%8D/%E2%80%8DO%20becomes%20CPU-bound&url=https%3A//death.andgravity.com/ptpe&via=_andgravity"
>Twitter</a>
</span>
</span></p>

<form
    action="https://gmail.us7.list-manage.com/subscribe/post?u=9909b0e978d8d8d941bd3c8dc&amp;id=c61d63d661&SIGNUP=ptpe"
    method="post"
    id="embedded-subscribe-form"
    name="mc-embedded-subscribe-form"
    target="_blank"
    novalidate
    class="panel subscribe-form"
>
    <div class="panel-header text-large">

        Want to know when new articles come out?

    </div>
    <div class="panel-body">

        <p>Drop your email in the box below and I'll send new stuff straight to your inbox!</p>

        <div class="form-group col-6 col-xs-12 col-md-9">
        <input type="text" name="FNAME" id="mce-FNAME"
            class="form-input input-lg"
            placeholder="Your first name"
        >
        </div>

        <div class="form-group col-6 col-xs-12 col-md-9">
        <input type="email" name="EMAIL" id="mce-EMAIL"
            class="form-input input-lg"
            placeholder="Your email address"
        >
        </div>

        <!-- bot prevention-->
        <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_9909b0e978d8d8d941bd3c8dc_c61d63d661" tabindex="-1" value=""></div>

    </div>
    <div class="panel-footer">

        <div class="form-group">
        <input type="submit"  name="subscribe" id="mc-embedded-subscribe"
            class="btn btn-primary btn-lg"
            value="Subscribe"
        >
        </div>

    </div>

</form>
<h2 id="bonus-free-threading">Bonus: free threading<span class="headerlink">&nbsp;<a href="#bonus-free-threading" title="permalink">#</a></span></h2>
<p>You may have heard people being excited
about the experimental <a class="external" href="https://docs.python.org/3/whatsnew/3.13.html#free-threaded-cpython">free threading</a> support added in Python 3.13,
which allows running Python code on multiple CPUs.</p>
<p>And for good reason:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="go">$ python3.13t</span>
<span class="go">Python 3.13.2 experimental free-threading build</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">bench</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init_client</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">))</span>
<span class="go">elapsed: 8.224</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">))</span>
<span class="go">elapsed: 6.193</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">120</span><span class="p">))</span>
<span class="go">elapsed: 2.323</span>
</code></pre></div>
<p><strong>3.6x</strong> over to the <a class="external" href="https://docs.python.org/3/glossary.html#term-global-interpreter-lock">GIL</a> version,
with none of the shenanigans in this article!</p>
<p>Alas, packages with extensions need to be updated to support it:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>
<span class="go">zsh: segmentation fault  python3.13t</span>
</code></pre></div>
<p>...but the ecosystem is <a class="external" href="https://hugovk.github.io/free-threaded-wheels/">slowly catching up</a>.</p>
<p><img class="img-responsive" src="/_file/ptpe/patient.jpg" alt="cat patiently waiting on balcony" /></p>



<div class="panel inline-panel" >
    <div class="panel-header text-large">
        If you&#39;ve made it this far, you might like:
    </div>
    <div class="panel-body">
        <p><a href="/lru-cache">
            This is not interview advice: a priority-expiry LRU cache in Python without heaps or trees
        </a>
    </div>
</div>
<section class="footnotes">
<ol>
<li id="fn-1"><p>At least, all we can use for pure-Python code.
I‍/‍O always releases the <a class="external" href="https://docs.python.org/3/glossary.html#term-global-interpreter-lock">global interpreter lock</a>,
and so do some extension modules. <a href="#fnref-1" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-2"><p>The psutil documentation for <a class="external" href="https://psutil.readthedocs.io/en/latest/#psutil.Process.memory_full_info">memory_full_info()</a>
explains the difference quite nicely and links to further resources,
because <a class="internal" href="/output#good-libraries-educate">good libraries educate</a>. <a href="#fnref-2" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-3"><p>You may have to run Python as root to get the USS of child processes. <a href="#fnref-3" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-4"><p>And no, <a class="external" href="https://docs.python.org/3/library/asyncio.html">asyncio</a> is not a solution,
since the event loop runs in a single thread,
so you'd still need to run one event loop per CPU in dedicated processes. <a href="#fnref-4" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-5"><p>We could have used <a class="external" href="https://en.wikipedia.org/wiki/Composition_over_inheritance">composition</a> instead,
but then we'd have to implement the full <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor">Executor</a> interface,
defining each method explicitly to delegate to the inner process pool executor,
and keep things up to date when the interface gets new methods
(and we'd have no way to trick the inner executor's <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map">map()</a> to use our <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.submit">submit()</a>,
so we'd have to implement it from scratch).</p>
<p>Yet another option would be to use both inheritance <em>and</em> composition –
inherit the <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor">Executor</a> base class directly for the <a class="external" href="https://github.com/python/cpython/blob/3.13/Lib/concurrent/futures/_base.py#L583-L648">common methods</a>
(assuming they're defined there and not in subclasses),
and delegate to the inner executor only where needed
(likely just <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map">map()</a> and <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.shutdown">shutdown()</a>).
But, the only difference from the current code would be
that it'd say <code>self._inner</code> instead of <code>super()</code> in a few places,
so it's not really worth it, in my opinion. <a href="#fnref-5" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-6"><p>A previous version of this code
attempted to <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.shutdown">shutdown()</a> the thread pool executor
using <a class="external" href="https://docs.python.org/3/library/atexit.html">atexit</a>,
but since <a class="external" href="https://docs.python.org/3/library/atexit.html">atexit</a> functions run <em>after</em> non-daemon threads finish,
it wasn't actually doing anything.
Not shutting it down seems to work for now,
but we may still need do it
to support <code>shutdown(​cancel_futures=​True)</code> properly. <a href="#fnref-6" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-7"><p>Check out
<a class="external" href="https://github.com/nilp0inter/threadedprocess">nilp0inter/threadedprocess</a>
for an idea of what that looks like. <a href="#fnref-7" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-8"><p><code>pkill -fn '[Pp]ython'</code> would've done it too,
but it gets tedious if you do it a lot,
and it's a different command on Windows. <a href="#fnref-8" class="footnote"><sup>[return]</sup></a></p></li>
</ol>
</section>








</div>
</main>


<footer class="footer">
<p class="text-gray">
<a href="/">home</a>
∙ <a href="/_feed/index.xml">feed</a>
∙ <a href="/about">about</a>

∙ © 2021 lemon24



</footer>


</div>