












<!doctype html>

<meta name="viewport" content="width=device-width, initial-scale=1" />

<link rel="stylesheet" href="/_static/spectre.css">
<link rel="stylesheet" href="/_static/pygments.css">
<link rel="stylesheet" href="/_static/style.css">

<link rel="alternate" type="application/atom+xml" title="Atom feed" href="/_feed/index.xml" />

<link rel="icon" href="/_static/xo-system-icon.svg">
<link rel="apple-touch-icon" href="/_static/xo-system-icon.svg">







<title>Process​ThreadPoolExecutor: for when IO becomes CPU bound - death and gravity</title>



<meta property="og:title" content="Process​ThreadPoolExecutor: for when IO becomes CPU bound">
<meta property="og:site_name" content="death and gravity">
<meta property="og:type" content="article">
<meta property="og:url" content="https://death.andgravity.com/ptpe">




<script>
/* https://css-tricks.com/the-trick-to-viewport-units-on-mobile/ */
function set_vh() {
    let vh = window.innerHeight * 0.01;
    document.documentElement.style.setProperty('--vh', `${vh}px`);
}
/* we do it once, now, *and* on every resize */
set_vh();
window.addEventListener('resize', set_vh);
</script>





<div class="main container grid-lg">


<header>
<nav>
<ul class="breadcrumb">

<li class="breadcrumb-item">
    <a href="/">death and gravity</a>
</li>

</ul>
</nav>

<h1 class="heading-noindex">Process​ThreadPoolExecutor: for when IO becomes CPU bound</h1>

<p class="text-gray text-nowrap">



<small>
<span class="tooltip" data-tooltip="published on 2025-04-01">April 2025</span>
∙ six minute read
∙
</small><span class="share-icons">
<a
    class="share-icon pycoders"
    href="https://pycoders.com/submissions"
    target="_blank"
>PyCoder's Weekly</a>
<a
    class="share-icon hacker-news"
    href="https://news.ycombinator.%63%6f%6d/submitlink?u=https%3A//death.andgravity.com/ptpe&t=Process%E2%80%8BThreadPoolExecutor%3A%20for%20when%20IO%20becomes%20CPU%20bound"
>HN</a>
<a
    class="share-icon reddit"
    href="https://www.reddit.%63%6f%6d/%73%75%62%6d%69%74?url=https%3A//death.andgravity.com/ptpe&title=Process%E2%80%8BThreadPoolExecutor%3A%20for%20when%20IO%20becomes%20CPU%20bound"
>Reddit</a>
<a
    class="share-icon linkedin"
    href="https://www.linkedin.%63%6f%6d/sharing/share-offsite/?url=https%3A//death.andgravity.com/ptpe"
>linkedin</a>
<a
    class="share-icon twitter"
    href="https://twitter.%63%6f%6d/%73%68%61%72%65?text=Process%E2%80%8BThreadPoolExecutor%3A%20for%20when%20IO%20becomes%20CPU%20bound&url=https%3A//death.andgravity.com/ptpe&via=_andgravity"
>Twitter</a>
</span>


</p>






</header>


<main class="content columns">
<div class="column col-sm-12 col-md-10 col-8">

<p>aside: asyncio in itself is no solution, you will saturate the (one) cpu/thread there too</p>
<section class="toc">
<ul>
<li><a href="#simulation-measurement-time">simulation/measurement time</a></li>
<li><a href="#baseline-threads">baseline threads</a></li>
<li><a href="#top">top</a></li>
<li><a href="#processes">processes</a></li>
<li><a href="#memory">memory</a></li>
<li><a href="#">...</a></li>
<li><a href="#a-minimal-plausible-solution">A minimal plausible solution</a></li>
<li><a href="#-1">...</a></li>
</ul>
</section>
<h2 id="simulation-measurement-time">simulation/measurement time<span class="headerlink">&nbsp;<a href="#simulation-measurement-time" title="permalink">#</a></span></h2>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Client</span><span class="p">:</span>
    <span class="n">io_time</span> <span class="o">=</span> <span class="mf">0.02</span>
    <span class="n">cpu_time</span> <span class="o">=</span> <span class="mf">0.0008</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="p">):</span>
        <span class="c1"># simulate I/O</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">io_time</span><span class="p">)</span>

        <span class="c1"># simulate CPU-bound work</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="k">while</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_time</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span> <span class="n">i</span> <span class="o">**</span> <span class="n">i</span>

        <span class="k">return</span> <span class="n">arg</span>
</code></pre></div>

<p>we could simulate a connection pool using a semaphore,
but that's not relevant for what we're trying to measure;
nevertheless, keep in mind the connection pool
is a resource we're trying to share between threads if possible</p>
<p>since we'll also use this from multiple processes,
we'll put the work in a function, and use a global client,
initialized by a function passed to e.g. ProcessPoolExecutor initializer=</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="n">client</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">init_client</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">client</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">do_stuff</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">client</span><span class="o">.</span><span class="n">method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>

<p>make ourselves a timing context manager</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">timer</span><span class="p">():</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">yield</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;elapsed: </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s2">1.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>we can then put these together in a benchmark function;
note the chunksize (again, nod to using processes late)</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">benchmark</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">timer</span><span class="o">=</span><span class="n">timer</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">executor</span><span class="p">:</span>
        <span class="c1"># make sure all the workers are started,</span>
        <span class="c1"># so we don&#39;t measure their startup time</span>
        <span class="nb">list</span><span class="p">(</span><span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">200</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">timer</span><span class="p">():</span>
            <span class="n">values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">do_stuff</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

        <span class="k">assert</span> <span class="n">values</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="n">values</span>
</code></pre></div>

<h2 id="baseline-threads">baseline threads<span class="headerlink">&nbsp;<a href="#baseline-threads" title="permalink">#</a></span></h2>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">client</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init_client</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="go">elapsed: 2.430</span>
</code></pre></div>
<p>more threads</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
<span class="go">elapsed: 1.259</span>
</code></pre></div>
<p>good. more!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">))</span>
<span class="go">elapsed: 0.875</span>
</code></pre></div>
<p>good. MORE!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">))</span>
<span class="go">elapsed: 0.872</span>
</code></pre></div>
<p>?! question mark cat</p>
<p>...</p>
<p>more?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>
<span class="go">elapsed: 0.874</span>
</code></pre></div>
<p>what in tarnation cat</p>
<h2 id="top">top<span class="headerlink">&nbsp;<a href="#top" title="permalink">#</a></span></h2>
<p>so, it's about time we look in more detail at what our process is doing</p>
<p>i'd normally go with the <a class="external" href="https://linux.die.net/man/1/top">top</a> command for this,
but since both the flags and the output vary with the operating system,
let's implement our own using the <a class="external" href="https://psutil.readthedocs.io/">psutil</a> library. (it might even work on windows)</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">top</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print information about current and child processes.</span>

<span class="sd">    RES is the resident set size. USS is the unique set size.</span>
<span class="sd">    %CPU is the CPU utilization. nTH is the number of threads.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">process</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span>
    <span class="n">processes</span> <span class="o">=</span> <span class="p">[</span><span class="n">process</span><span class="p">]</span> <span class="o">+</span> <span class="n">process</span><span class="o">.</span><span class="n">children</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">cpu_percent</span><span class="p">()</span>

    <span class="k">yield</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;PID&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;RES&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;USS&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;%CPU&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;nTH&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">memory_full_info</span><span class="p">()</span>
        <span class="k">except</span> <span class="n">psutil</span><span class="o">.</span><span class="n">AccessDenied</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span>
        <span class="n">rss</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>
        <span class="n">uss</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;uss&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>
</code></pre></div>

<p>since it's a context manager, we can use it instead of the timer
(how convenient :)</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">client</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init_client</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   16.8m   13.2m    70.7      21</span>
</code></pre></div>
<p>so what happens if we increase the number of threads?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   17.0m   13.4m    99.1      31</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   17.3m   13.7m   100.9      41</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   17.6m   14.0m   101.4      51</span>
</code></pre></div>
<p>uh oh</p>
<p>so, it looks like with enough threads,
the cpu-bound part of our mostly io-bound task becomes dominant,
saturating the CPU
(and we can't use more than one CPU with threads alone
because of the GIL,
although that may change in a few python versions)</p>
<h2 id="processes">processes<span class="headerlink">&nbsp;<a href="#processes" title="permalink">#</a></span></h2>
<p>i know, let's use ProcessPoolExecutor instead!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 2.500</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 1.446</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 1.110</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 0.750</span>
</code></pre></div>
<p>a bit more time for 10-30 processes, likely due to ipc overhead,
but for 40 processes it's a bit faster than with threads</p>
<p>more? more!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 0.633</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 0.501</span>
</code></pre></div>
<p>note these are the minimums of multiple runs,
most of them aren't as good.</p>
<p>it's faster, but ... for twice the number of processes,
it became only 33% faster.
and it's only 43% faster than using 40 threads,
when it theory now it can use 4 times as many CPUs.</p>
<p>also, if our client connects to many different hosts,
like a requests Session would,
we're not making the best use of the connection pooling,
since we now have 80 connection pools!
(this isn't that big of an issue if our client talks to just one host,
like an aws client would, since each pool would end up having just one connection)</p>
<h2 id="memory">memory<span class="headerlink">&nbsp;<a href="#memory" title="permalink">#</a></span></h2>
<p>but it gets worse!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  14516   14.8m   11.1m     9.2       3</span>
<span class="go">  14518    9.5m    6.4m     0.0       1</span>
<span class="go">  14519   12.6m    9.0m     2.3       1</span>
<span class="go">  ... 78 more lines ...</span>
<span class="go">  14598   12.5m    9.0m    13.3       1</span>
</code></pre></div>
<p>12.5 MiB * 80 ~= 1 GiB ... that's a lot of memory...</p>
<p>now, there's some nuance to be had here.</p>
<p>First, on most operating systems that use virtual memory,
<a class="external" href="https://en.wikipedia.org/wiki/Code_segment">code segment</a> pages are usually shared between processes
(there's no point in having the same Python interpreter binary in memory 80 times).</p>
<p>The <a class="external" href="https://en.wikipedia.org/wiki/Unique_set_size">unique set size</a> is probably a better measurement than the <a class="external" href="https://en.wikipedia.org/wiki/Resident_set_size">resident set size</a>,
since it excludes memory shared between processes.<sup class="footnote-ref" id="fnref-1"><a href="#fn-1">1</a></sup>
So, for the output above, from macOS<sup class="footnote-ref" id="fnref-2"><a href="#fn-2">2</a></sup>,
the actual usage is more like 9 MiB * 80 ~= 720 MiB
(excluding memory taken by the main process to make the math easier).</p>
<p>Second, if you use the <em>fork</em> (or <em>forkserver</em>) <a class="external" href="https://docs.python.org/3.14/library/multiprocessing.html#contexts-and-start-methods">start method</a>,
processes also share memory allocated before the <a class="external" href="https://en.wikipedia.org/wiki/Fork_(system_call)">fork()</a> call
through a mechanism called <a class="external" href="https://en.wikipedia.org/wiki/Copy-on-write#In_virtual_memory_management">copy-on-write</a>;
for Python, this includes modules and (global) variables.</p>
<p>On Linux, for example:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go"> 259344   14.4m    3.8m     5.2       3</span>
<span class="go"> 259357   13.1m    1.7m     0.0       1</span>
<span class="go">  ... 78 more lines ...</span>
<span class="go"> 259436   13.3m    1.8m     0.0       1</span>
</code></pre></div>
<p>...the actual usage is more like 1.7 MiB * 80 = 136 MiB.</p>
<p>of course, that's only a lower bound –
once each process starts doing actual work,
memory allocated for that will not be shared.</p>
<h2 id="">...<span class="headerlink">&nbsp;<a href="#" title="permalink">#</a></span></h2>
<p>one reasonable way of dealing with this
would be to split the input into multiple batches,
once per CPU, and pass them to a process executor,
which in turn runs the batch in a thread executor</p>
<p>but this means we'd need to change our code, and that's no fun;
if we could only have an executor that magically spreads the work
across multiple processes and threads</p>
<h2 id="a-minimal-plausible-solution">A minimal plausible solution<span class="headerlink">&nbsp;<a href="#a-minimal-plausible-solution" title="permalink">#</a></span></h2>
<p>in line with what I hope has
<a class="internal" href="/pwned#a-minimal-plausible-solution">become</a>
<a class="internal" href="/lru-cache#a-minimal-plausible-solution">tradition</a>
by now,
we'll take an iterative, <a class="external" href="https://hintjens.gitbooks.io/scalable-c/content/chapter1.html#problem-what-do-we-do-next">problem-solution</a> approach to this;
since we're <em>not sure what to do yet</em>,
we start with <a class="external" href="https://wiki.c2.com/?DoTheSimplestThingThatCouldPossiblyWork">the simplest thing that could possibly work</a>.</p>
<p>we know we want to have a process pool executor
that starts one thread pool executor in each process,
so let's deal with that first.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ProcessPoolExecutor</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">initializer</span><span class="o">=</span><span class="n">_init_process</span><span class="p">,</span>
            <span class="n">initargs</span><span class="o">=</span><span class="p">(</span><span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<p>subclassing ProcessPoolExecutor gives us the map() implementation for free.
by not passing any max_workers to super(),
we get the default of one process per CPU;
the rest of the arguments we can add later.</p>
<p>we pass the user-defined (process) initializer and arguments
to our own, custom initializer,
so we can set up a global ThreadPoolExecutor
before calling them.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="n">_executor</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_init_process</span><span class="p">(</span><span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_executor</span>

    <span class="n">_executor</span> <span class="o">=</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_threads</span><span class="p">)</span>
    <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">initializer</span><span class="p">:</span>
        <span class="n">initializer</span><span class="p">(</span><span class="o">*</span><span class="n">initargs</span><span class="p">)</span>
</code></pre></div>

<p>like the <code>__init__</code> arguments,
we also have to pass the arguments to submit()
along to a custom function that can submit the work
to the ThreadPoolExecutor instead</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ProcessPoolExecutor</span><span class="p">):</span>
    <span class="c1"># ...</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">submit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_submit</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

<p>...kinda like this:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

<p>ok, that looks good enough;
let's use it and see if it works:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_do_stuff</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;doing </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">n</span> <span class="o">**</span> <span class="mi">2</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">ProcessThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_do_stuff</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])))</span>
</code></pre></div>

<p>here goes:</p>
<div class="highlight code-container"><pre class="code" data-lang="Bash Session"><span></span><code><span class="gp">$ </span>python<span class="w"> </span>ptpe.py
<span class="go">doing 0</span>
<span class="go">doing 1</span>
<span class="go">doing 2</span>
<span class="go">concurrent.futures.process._RemoteTraceback:</span>
<span class="go">&quot;&quot;&quot;</span>
<span class="go">Traceback (most recent call last):</span>
<span class="go">  File &quot;concurrent/futures/process.py&quot;, line 212, in _sendback_result</span>
<span class="go">    result_queue.put(_ResultItem(work_id, result=result,</span>
<span class="go">  File &quot;multiprocessing/queues.py&quot;, line 371, in put</span>
<span class="go">    obj = _ForkingPickler.dumps(obj)</span>
<span class="go">  File &quot;multiprocessing/reduction.py&quot;, line 51, in dumps</span>
<span class="go">    cls(buf, protocol).dump(obj)</span>
<span class="go">TypeError: cannot pickle &#39;_thread.RLock&#39; object</span>
<span class="go">&quot;&quot;&quot;</span>

<span class="go">The above exception was the direct cause of the following exception:</span>

<span class="go">Traceback (most recent call last):</span>
<span class="go">  ...</span>
<span class="go">TypeError: cannot pickle &#39;_thread.RLock&#39; object</span>
</code></pre></div>
<p>so, the work started, since we're seeing the <code>doing ...</code> lines,
but the Future returned by the thread pool executor can't be pickled;
not surprising, to be honest, it couldn't have been that easy</p>
<h2 id="-1">...<span class="headerlink">&nbsp;<a href="#-1" title="permalink">#</a></span></h2>
<p>traceback above has hint, use a queue to send back results</p>
<section class="footnotes">
<ol>
<li id="fn-1"><p>psutil <a class="external" href="https://psutil.readthedocs.io/en/latest/#psutil.Process.memory_full_info">memory_full_info()</a> explain the difference quite nicely
(<a class="internal" href="/output#good-libraries-educate">good libraries educate</a>). <a href="#fnref-1" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-2"><p>note that on macOS I had to run Python with sudo
to be able to get USS for child processes <a href="#fnref-2" class="footnote"><sup>[return]</sup></a></p></li>
</ol>
</section>








</div>
</main>


<footer class="footer">
<p class="text-gray">
<a href="/">home</a>
∙ <a href="/_feed/index.xml">feed</a>
∙ <a href="/about">about</a>

∙ © 2021 lemon24



</footer>


</div>