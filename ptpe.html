












<!doctype html>

<meta name="viewport" content="width=device-width, initial-scale=1" />

<link rel="stylesheet" href="/_static/spectre.css">
<link rel="stylesheet" href="/_static/pygments.css">
<link rel="stylesheet" href="/_static/style.css">

<link rel="alternate" type="application/atom+xml" title="Atom feed" href="/_feed/index.xml" />

<link rel="icon" href="/_static/xo-system-icon.svg">
<link rel="apple-touch-icon" href="/_static/xo-system-icon.svg">







<title>Process​ThreadPoolExecutor: for when IO becomes CPU bound - death and gravity</title>



<meta property="og:title" content="Process​ThreadPoolExecutor: for when IO becomes CPU bound">
<meta property="og:site_name" content="death and gravity">
<meta property="og:type" content="article">
<meta property="og:url" content="https://death.andgravity.com/ptpe">




<script>
/* https://css-tricks.com/the-trick-to-viewport-units-on-mobile/ */
function set_vh() {
    let vh = window.innerHeight * 0.01;
    document.documentElement.style.setProperty('--vh', `${vh}px`);
}
/* we do it once, now, *and* on every resize */
set_vh();
window.addEventListener('resize', set_vh);
</script>





<div class="main container grid-lg">


<header>
<nav>
<ul class="breadcrumb">

<li class="breadcrumb-item">
    <a href="/">death and gravity</a>
</li>

</ul>
</nav>

<h1 class="heading-noindex">Process​ThreadPoolExecutor: for when IO becomes CPU bound</h1>

<p class="text-gray text-nowrap">



<small>
<span class="tooltip" data-tooltip="published on 2025-04-01">April 2025</span>
∙ 13 minute read
∙
</small><span class="share-icons">
<a
    class="share-icon pycoders"
    href="https://pycoders.com/submissions"
    target="_blank"
>PyCoder's Weekly</a>
<a
    class="share-icon hacker-news"
    href="https://news.ycombinator.%63%6f%6d/submitlink?u=https%3A//death.andgravity.com/ptpe&t=Process%E2%80%8BThreadPoolExecutor%3A%20for%20when%20IO%20becomes%20CPU%20bound"
>HN</a>
<a
    class="share-icon reddit"
    href="https://www.reddit.%63%6f%6d/%73%75%62%6d%69%74?url=https%3A//death.andgravity.com/ptpe&title=Process%E2%80%8BThreadPoolExecutor%3A%20for%20when%20IO%20becomes%20CPU%20bound"
>Reddit</a>
<a
    class="share-icon linkedin"
    href="https://www.linkedin.%63%6f%6d/sharing/share-offsite/?url=https%3A//death.andgravity.com/ptpe"
>linkedin</a>
<a
    class="share-icon twitter"
    href="https://twitter.%63%6f%6d/%73%68%61%72%65?text=Process%E2%80%8BThreadPoolExecutor%3A%20for%20when%20IO%20becomes%20CPU%20bound&url=https%3A//death.andgravity.com/ptpe&via=_andgravity"
>Twitter</a>
</span>


</p>






</header>


<main class="content columns">
<div class="column col-sm-12 col-md-10 col-8">

<p>aside: asyncio in itself is no solution, you will saturate the (one) cpu/thread there too</p>
<section class="toc">
<ul>
<li><a href="#establishing-a-baseline">Establishing a baseline</a>
<ul>
<li><a href="#threads">Threads</a></li>
<li><a href="#problem-cpu-becomes-a-bottleneck-when-you-do-enough-i-o">Problem: CPU becomes a bottleneck when you do enough I‍/‍O</a></li>
<li><a href="#processes">Processes?</a></li>
<li><a href="#problem-processes-use-more-memory">Problem: processes use more memory</a></li>
</ul>
</li>
<li><a href="#">...</a></li>
<li><a href="#a-minimal-plausible-solution">A minimal plausible solution</a></li>
<li><a href="#getting-results-back">getting results back</a></li>
<li><a href="#matching-results-to-futures">matching results to futures</a></li>
<li><a href="#dead-workers">dead workers</a></li>
<li><a href="#bonus-free-threading">Bonus: free threading</a></li>
</ul>
</section>
<h2 id="establishing-a-baseline">Establishing a baseline<span class="headerlink">&nbsp;<a href="#establishing-a-baseline" title="permalink">#</a></span></h2>
<p>To showcase the problem,
we'll use a client that pretends to do <a class="external" href="https://en.wikipedia.org/wiki/I%E2%80%8D/%E2%80%8DO_bound">mostly I‍/‍O</a>,
with a sprinkling of <a class="external" href="https://en.wikipedia.org/wiki/CPU-bound">CPU-bound</a> work thrown in
– a stand-in for something like a database connection,
a Requests <a class="external" href="https://requests.readthedocs.io/en/latest/user/advanced/#session-objects">session</a> or a Boto3 <a class="external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client">DynamoDB client</a>.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Client</span><span class="p">:</span>
    <span class="n">io_time</span> <span class="o">=</span> <span class="mf">0.02</span>
    <span class="n">cpu_time</span> <span class="o">=</span> <span class="mf">0.0008</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="p">):</span>
        <span class="c1"># simulate I/O</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">io_time</span><span class="p">)</span>

        <span class="c1"># simulate CPU-bound work</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="k">while</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_time</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span> <span class="n">i</span> <span class="o">**</span> <span class="n">i</span>

        <span class="k">return</span> <span class="n">arg</span>
</code></pre></div>

<p>We use <a class="external" href="https://docs.python.org/3/library/time.html#time.sleep">sleep()</a> for I‍/‍O, an do some math in a loop for the CPU stuff.
It doesn't exactly matter how long each takes,
as long as time spent doing I‍/‍O dominates.</p>
<p>Real clients meant to be shared between threads
are usually backed by a connection pool
to allow connection reuse;
we could simulate one using a <a class="external" href="https://docs.python.org/3/library/threading.html#semaphore-objects">semaphore</a>,
but it's not relevant here
– we're assuming the connection pool is effectively unbounded.</p>
<p>Since we'll also use this from multiple processes,
we set up a global function that uses a global client
to be created by an <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor">executor</a>'s <code>initializer</code>;
we could just do it on first use,
but this way it's obvious who is creating the client.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="n">client</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">init_client</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">client</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">do_stuff</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">client</span><span class="o">.</span><span class="n">method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>

<p>Finally, we make a timing context manager:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">timer</span><span class="p">():</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">yield</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;elapsed: </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s2">1.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>...and put everything together in a benchmark function
that uses the client a bunch of times in parallel
using a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html">concurrent.futures</a> executor:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">benchmark</span><span class="p">(</span><span class="n">executor</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">timer</span><span class="o">=</span><span class="n">timer</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">executor</span><span class="p">:</span>
        <span class="c1"># make sure all the workers are started,</span>
        <span class="c1"># so we don&#39;t measure their startup time</span>
        <span class="nb">list</span><span class="p">(</span><span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">200</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">timer</span><span class="p">():</span>
            <span class="n">values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">do_stuff</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">chunksize</span><span class="p">))</span>

        <span class="k">assert</span> <span class="n">values</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="n">values</span>
</code></pre></div>

<h3 id="threads">Threads<span class="headerlink">&nbsp;<a href="#threads" title="permalink">#</a></span></h3>
<!-- FIXME: note about python version and computer used -->
<p>So, a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor">ThreadPoolExecutor</a> should suffice here,
since we're mostly doing I‍/‍O, right?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">bench</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init_client</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="go">elapsed: 24.693</span>
</code></pre></div>
<p>More threads!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
<span class="go">elapsed: 12.405</span>
</code></pre></div>
<p>Good, doubling the threads makes it twice as fast. More!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">))</span>
<span class="go">elapsed: 8.718</span>
</code></pre></div>
<p>Good, three times the threads makes it three times faster. MORE!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">))</span>
<span class="go">elapsed: 8.638</span>
</code></pre></div>
<p><img class="img-responsive" src="/_file/ptpe/confused.jpg" alt="confused cat with question marks around its head" /></p>
<p>... more?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>
<span class="go">elapsed: 8.458</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">60</span><span class="p">))</span>
<span class="go">elapsed: 8.430</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">70</span><span class="p">))</span>
<span class="go">elapsed: 8.428</span>
</code></pre></div>
<!-- ![confused cat with raised eyebrow collage](attachment:confused2.jpg) -->
<!-- !["what in tarnation" shiba inu dog wearing a cowboy hat](attachment:tarnation.jpg) -->
<!-- !["what in tarnation?" cat wearing a cowboy hat](attachment:tarnation2.jpg) -->
<!-- ![confused cat snarling](attachment:wtf.jpg) -->
<p><img class="img-responsive" src="/_file/ptpe/concern.jpg" alt="concerned cat looking at reader" /></p>
<h3 id="problem-cpu-becomes-a-bottleneck-when-you-do-enough-i-o">Problem: CPU becomes a bottleneck when you do enough I‍/‍O<span class="headerlink">&nbsp;<a href="#problem-cpu-becomes-a-bottleneck-when-you-do-enough-i-o" title="permalink">#</a></span></h3>
<p>It's time we take a closer look at what our process is doing.</p>
<p>I'd normally use the <a class="external" href="https://linux.die.net/man/1/top">top</a> command for this,
but since both the flags and the output vary with the operating system,
we'll implement our own using the excellent <a class="external" href="https://psutil.readthedocs.io/">psutil</a> library.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">top</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print information about current and child processes.</span>

<span class="sd">    RES is the resident set size. USS is the unique set size.</span>
<span class="sd">    %CPU is the CPU utilization. nTH is the number of threads.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">process</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span>
    <span class="n">processes</span> <span class="o">=</span> <span class="p">[</span><span class="n">process</span><span class="p">]</span> <span class="o">+</span> <span class="n">process</span><span class="o">.</span><span class="n">children</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">cpu_percent</span><span class="p">()</span>

    <span class="k">yield</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;PID&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;RES&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;USS&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;%CPU&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;nTH&#39;</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">memory_full_info</span><span class="p">()</span>
        <span class="k">except</span> <span class="n">psutil</span><span class="o">.</span><span class="n">AccessDenied</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">memory_info</span><span class="p">()</span>
        <span class="n">rss</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">rss</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>
        <span class="n">uss</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;uss&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>
        <span class="n">cpu</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cpu_percent</span><span class="p">()</span>
        <span class="n">nth</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">num_threads</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">pid</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">rss</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2">m </span><span class="si">{</span><span class="n">uss</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2">m </span><span class="si">{</span><span class="n">cpu</span><span class="si">:</span><span class="s2">7.1f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">nth</span><span class="si">:</span><span class="s2">&gt;7</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Because it's a context manager, we can use it as a timer ;)</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">init_client</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  51395   35.2m   28.5m    38.7      11</span>
</code></pre></div>
<p>So, what happens if we increase the number of threads?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   16.8m   13.2m    70.7      21</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   17.0m   13.4m    99.1      31</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">  13912   17.3m   13.7m   100.9      41</span>
</code></pre></div>
<p>It looks like the more threads we have,
the more the compute part of our I/O bound workload increases,
eventually becoming high enough to saturate one CPU
– and due to the <a class="external" href="https://docs.python.org/3/glossary.html#term-global-interpreter-lock">global interpreter lock</a>,
we can use <em>at most one CPU</em> for pure-Python code,
regardless of the number of threads.</p>
<!-- FIXME: if you know something the others don't, wait until the end ;) -->
<h3 id="processes">Processes?<span class="headerlink">&nbsp;<a href="#processes" title="permalink">#</a></span></h3>
<p>I know, let's use a <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor">ProcessPoolExecutor</a> instead!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 12.374</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 8.330</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 6.273</span>
</code></pre></div>
<p>Hmmm... I guess it <em>is</em> a little bit better.</p>
<p>More? More!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 4.751</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 3.785</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 3.824</span>
</code></pre></div>
<p>It's faster, but with diminishing returns
– after 80 processes, there's no more improvement;
and even then, it's only 2.2x faster than the best time with threads,
when, in theory, it can now use all 4 CPUs.</p>
<p>Also, we're not making the best use of connection pooling
(relevant if the client connects to many different hosts,
since we now have 80 distinct connection pools),
or multiplexing
(relevant with protocols like HTTP/2 or newer,
since we now have 80 distinct connections).</p>
<h3 id="problem-processes-use-more-memory">Problem: processes use more memory<span class="headerlink">&nbsp;<a href="#problem-processes-use-more-memory" title="permalink">#</a></span></h3>
<p>But it gets worse!</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go">   2479   21.2m   15.4m    15.0       3</span>
<span class="go">   2480   11.2m    6.3m     0.0       1</span>
<span class="go">   2481   13.8m    8.5m     3.4       1</span>
<span class="go">  ... 78 more lines ...</span>
<span class="go">   2560   13.8m    8.5m     4.4       1</span>
</code></pre></div>
<p>13.8 MiB * 80 ~= 1 GiB ... that is <em>a lot</em> of memory.</p>
<p><strong>Now, there's some nuance to be had here.</strong></p>
<p>First, on most operating systems that use virtual memory,
<a class="external" href="https://en.wikipedia.org/wiki/Code_segment">code segment</a> pages are usually shared between processes
(there's no point in having 80 separate copies
of the Python interpreter in memory).</p>
<p>The <a class="external" href="https://en.wikipedia.org/wiki/Unique_set_size">unique set size</a> is probably a better measurement
than the <a class="external" href="https://en.wikipedia.org/wiki/Resident_set_size">resident set size</a>,
since it excludes memory shared between processes.<sup class="footnote-ref" id="fnref-1"><a href="#fn-1">1</a></sup>
So, for the macOS<sup class="footnote-ref" id="fnref-2"><a href="#fn-2">2</a></sup> output above,
the actual usage is more like 8.5 MiB * 80 = 680 MiB.</p>
<p>Second, if you use the <em>fork</em> or <em>forkserver</em> <a class="external" href="https://docs.python.org/3.14/library/multiprocessing.html#contexts-and-start-methods">start methods</a>,
processes also share memory allocated before the <a class="external" href="https://en.wikipedia.org/wiki/Fork_(system_call)">fork()</a> via <a class="external" href="https://en.wikipedia.org/wiki/Copy-on-write#In_virtual_memory_management">copy-on-write</a>;
for Python, this includes module code and (global) variables.</p>
<p>On Linux, for example,
the actual usage is 1.7 MiB * 80 = 136 MiB:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">top</span><span class="p">)</span>
<span class="go">    PID     RES     USS    %CPU     nTH</span>
<span class="go"> 329801   17.0m    6.6m     5.1       3</span>
<span class="go"> 329802   13.3m    1.6m     2.1       1</span>
<span class="go">  ... 78 more lines ...</span>
<span class="go"> 329881   13.3m    1.7m     2.0       1</span>
</code></pre></div>
<p>However,  that's only a lower bound –
once the processes start doing real work,
new memory allocated for that is not shared.</p>
<h2 id="">...<span class="headerlink">&nbsp;<a href="#" title="permalink">#</a></span></h2>
<p>one reasonable way of dealing with this
would be to split the input into multiple batches,
once per CPU, and pass them to a process executor,
which in turn runs the batch in a thread executor</p>
<p>but this means we'd need to change our code, and that's no fun;
if we could only have an executor that magically spreads the work
across multiple processes and threads</p>
<h2 id="a-minimal-plausible-solution">A minimal plausible solution<span class="headerlink">&nbsp;<a href="#a-minimal-plausible-solution" title="permalink">#</a></span></h2>
<p>in line with what I hope has
<a class="internal" href="/pwned#a-minimal-plausible-solution">become</a>
<a class="internal" href="/lru-cache#a-minimal-plausible-solution">tradition</a>
by now,
we'll take an iterative, <a class="external" href="https://hintjens.gitbooks.io/scalable-c/content/chapter1.html#problem-what-do-we-do-next">problem-solution</a> approach to this;
since we're <em>not sure what to do yet</em>,
we start with <a class="external" href="https://wiki.c2.com/?DoTheSimplestThingThatCouldPossiblyWork">the simplest thing that could possibly work</a>.</p>
<p>we know we want to have a process pool executor
that starts one thread pool executor in each process,
so let's deal with that first.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ProcessPoolExecutor</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">initializer</span><span class="o">=</span><span class="n">_init_process</span><span class="p">,</span>
            <span class="n">initargs</span><span class="o">=</span><span class="p">(</span><span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<p>subclassing ProcessPoolExecutor gives us the map() implementation for free.
by not passing any max_workers to super(),
we get the default of one process per CPU;
the rest of the arguments we can add later.</p>
<p>we pass the user-defined (process) initializer and arguments
to our own, custom initializer,
so we can set up a global ThreadPoolExecutor
before calling them.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="n">_executor</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_init_process</span><span class="p">(</span><span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_executor</span>

    <span class="n">_executor</span> <span class="o">=</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_threads</span><span class="p">)</span>
    <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">initializer</span><span class="p">:</span>
        <span class="n">initializer</span><span class="p">(</span><span class="o">*</span><span class="n">initargs</span><span class="p">)</span>
</code></pre></div>

<p>like the <code>__init__</code> arguments,
we also have to pass the arguments to submit()
along to a custom function that can submit the work
to the ThreadPoolExecutor instead</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ProcessPoolExecutor</span><span class="p">):</span>
    <span class="c1"># ...</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">submit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_submit</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

<p>...kinda like this:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

<p>ok, that looks good enough;
let's use it and see if it works:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_do_stuff</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;doing: </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">n</span> <span class="o">**</span> <span class="mi">2</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">ProcessThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_do_stuff</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])))</span>
</code></pre></div>

<p>here goes:</p>
<div class="highlight code-container"><pre class="code" data-lang="Bash Session"><span></span><code><span class="gp">$ </span>python<span class="w"> </span>ptpe.py
<span class="go">doing: 0</span>
<span class="go">doing: 1</span>
<span class="go">doing: 2</span>
<span class="go">concurrent.futures.process._RemoteTraceback:</span>
<span class="go">&quot;&quot;&quot;</span>
<span class="go">Traceback (most recent call last):</span>
<span class="go">  File &quot;concurrent/futures/process.py&quot;, line 210, in _sendback_result</span>
<span class="go">    result_queue.put(_ResultItem(work_id, result=result,</span>
<span class="go">  File &quot;multiprocessing/queues.py&quot;, line 391, in put</span>
<span class="go">    obj = _ForkingPickler.dumps(obj)</span>
<span class="go">  File &quot;multiprocessing/reduction.py&quot;, line 51, in dumps</span>
<span class="go">    cls(buf, protocol).dump(obj)</span>
<span class="go">TypeError: cannot pickle &#39;_thread.RLock&#39; object</span>
<span class="go">&quot;&quot;&quot;</span>

<span class="go">The above exception was the direct cause of the following exception:</span>

<span class="go">Traceback (most recent call last):</span>
<span class="go">  File &quot;ptpe.py&quot;, line 42, in &lt;module&gt;</span>
<span class="go">    print(list(e.map(_do_stuff, [0, 1, 2])))</span>
<span class="go">  ...</span>
<span class="go">TypeError: cannot pickle &#39;_thread.RLock&#39; object</span>
</code></pre></div>
<p>so, the work started, since we're seeing the <code>doing: ...</code> lines,
but the Future returned by the thread pool executor can't be pickled;
not surprising, to be honest, it couldn't have been that easy</p>
<hr />
<!-- TODO: consider reordering this so that it's first -->
<p>What if we wait for the result on the worker side?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
</code></pre></div>

<div class="highlight code-container"><pre class="code" data-lang="Bash Session"><span></span><code><span class="gp"> $ </span>python<span class="w"> </span>ptpe.py
<span class="go">doing: 0</span>
<span class="go">doing: 1</span>
<span class="go">doing: 2</span>
<span class="go">[0, 1, 4]</span>
</code></pre></div>
<p>it works?!</p>
<p>let's measure it:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">bench</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ptpe</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="go">elapsed: 6.161</span>
</code></pre></div>
<p>hmmmm... that's unexpectedly slow ...almost as if:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="go">elapsed: 6.067</span>
</code></pre></div>
<p>ah.
result() waits in _submit(),
which runs in the worker main thread,
making this just a ProcessPoolExecutor with extra steps</p>
<h2 id="getting-results-back">getting results back<span class="headerlink">&nbsp;<a href="#getting-results-back" title="permalink">#</a></span></h2>
<p>if we look carefully at the traceback above,
we can find a hint of how we can get the results back faster.
ProcessPoolExecutor seems to be using a result queue;
if we look at its <a class="external" href="https://github.com/python/cpython/blob/3.13/Lib/concurrent/futures/process.py">source code</a>
(linked from the <a class="external" href="https://docs.python.org/3/library/concurrent.futures.html">documentation</a>),
we even find this neat data-flow diagram:</p>
<pre class="code code-container"><code>|======================= In-process =====================|== Out-of-process ==|

+----------+     +----------+       +--------+     +-----------+    +---------+
|          |  =&gt; | Work Ids |       |        |     | Call Q    |    | Process |
|          |     +----------+       |        |     +-----------+    |  Pool   |
|          |     | ...      |       |        |     | ...       |    +---------+
|          |     | 6        |    =&gt; |        |  =&gt; | 5, call() | =&gt; |         |
|          |     | 7        |       |        |     | ...       |    |         |
| Process  |     | ...      |       | Local  |     +-----------+    | Process |
|  Pool    |     +----------+       | Worker |                      |  #1..n  |
| Executor |                        | Thread |                      |         |
|          |     +----------- +     |        |     +-----------+    |         |
|          | &lt;=&gt; | Work Items | &lt;=&gt; |        | &lt;=  | Result Q  | &lt;= |         |
|          |     +------------+     |        |     +-----------+    |         |
|          |     | 6: call()  |     |        |     | ...       |    |         |
|          |     |    future  |     |        |     | 4, result |    |         |
|          |     | ...        |     |        |     | 3, except |    |         |
+----------+     +------------+     +--------+     +-----------+    +---------+
</code></pre>
<p>now, we could probably use ProcessPoolExecutor's own result queue,
but that would involve touching a lot of (private) internals;<sup class="footnote-ref" id="fnref-3"><a href="#fn-3">3</a></sup>
instead, we can use our own, separate queue.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">initializer</span><span class="o">=</span><span class="n">_init_process</span><span class="p">,</span>
            <span class="n">initargs</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="p">,</span> <span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<p>Note we're using <a class="external" href="https://docs.python.org/3/tutorial/classes.html#tut-private">double underscores</a> for <code>__result_queue</code>,
since ProcessPoolExecutor already has a <code>_result_queue</code> attribute.</p>
<p>We pass the queue to each worker,
and on the worker side, we make it globally accessible:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="n">_executor</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">_result_queue</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_init_process</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">max_threads</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">initargs</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_executor</span><span class="p">,</span> <span class="n">_result_queue</span>

    <span class="n">_executor</span> <span class="o">=</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_threads</span><span class="p">)</span>
    <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">)</span>

    <span class="n">_result_queue</span> <span class="o">=</span> <span class="n">queue</span>
    <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">_result_queue</span><span class="o">.</span><span class="n">close</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">initializer</span><span class="p">:</span>
        <span class="n">initializer</span><span class="p">(</span><span class="o">*</span><span class="n">initargs</span><span class="p">)</span>
</code></pre></div>

<p>...so it can be used in callback registered in _submit:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">task</span><span class="o">.</span><span class="n">add_done_callback</span><span class="p">(</span><span class="n">_put_result</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_put_result</span><span class="p">(</span><span class="n">task</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">exception</span> <span class="o">:=</span> <span class="n">task</span><span class="o">.</span><span class="n">exception</span><span class="p">():</span>
        <span class="n">_result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="kc">False</span><span class="p">,</span> <span class="n">exception</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="kc">True</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
</code></pre></div>

<p>Back in the main process, we need to do something with the results.
Either way, we'll have a background thread that waits on the queue.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="c1"># ...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__result_handler</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__handle_results</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__result_handler</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</code></pre></div>

<p>For now, let's just print them:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__handle_results</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">ok</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;ok&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">ok</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;error&#39;</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>since we need a way to tell the thread to end,
we use None as a <a class="internal" href="/sentinels#what-s-a-sentinel-and-why-do-i-need-one">sentinel</a>,
which we pass when the executor shuts down:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">shutdown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">shutdown</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="n">wait</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">wait</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__result_handler</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span> <span class="o">=</span> <span class="kc">None</span>

</code></pre></div>

<p>let's see if it works:</p>
<div class="highlight code-container"><pre class="code" data-lang="Bash Session"><span></span><code><span class="gp">$ </span>python<span class="w"> </span>ptpe.py
<span class="go">doing: 0</span>
<span class="go">doing: 1</span>
<span class="go">ok: [0]</span>
<span class="go">doing: 2</span>
<span class="go">ok: [1]</span>
<span class="go">Traceback (most recent call last):</span>
<span class="go">  File &quot;ptpe.py&quot;, line 69, in &lt;module&gt;</span>
<span class="go">    print(list(e.map(_do_stuff, [0, 1, 2])))</span>
<span class="go">  File &quot;concurrent/futures/process.py&quot;, line 618, in _chain_from_iterable_of_lists</span>
<span class="go">    element.reverse()</span>
<span class="go">AttributeError: &#39;NoneType&#39; object has no attribute &#39;reverse&#39;</span>
</code></pre></div>
<p>it kinda works – we can see the <code>ok: ...</code> lines printed by the handler thread.</p>
<p>the error is because map()
expects the result of the Future returned by submit()
to be the return value of <code>fn()</code>
(the result of the work),
but instead it gets the return value of <code>_submit()</code>
(the result of <em>enqueing</em> the work).</p>
<h2 id="matching-results-to-futures">matching results to futures<span class="headerlink">&nbsp;<a href="#matching-results-to-futures" title="permalink">#</a></span></h2>
<p>so, we'll make our own futures:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_threads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initargs</span><span class="o">=</span><span class="p">()):</span>
        <span class="c1"># ...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__result_handler</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__handle_results</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__result_handler</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</code></pre></div>

<p>in order to map the result back to its future,
we need some sort unique id;
the id() of the outer future should do,
since it's guaranteed unique during its lifetime.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">submit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">outer</span> <span class="o">=</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">Future</span><span class="p">()</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="nb">id</span><span class="p">(</span><span class="n">outer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">outer</span>

        <span class="n">outer</span><span class="o">.</span><span class="n">set_running_or_notify_cancel</span><span class="p">()</span>
        <span class="n">inner</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_submit</span><span class="p">,</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outer</span>
</code></pre></div>

<p>the id gets passed to <code>_submit()</code>,
which in turn passes it to <code>_put_result()</code>
by setting it as an attribute on the task,
which in turn puts it on the queue with the result:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">_submit</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">_executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">task</span><span class="o">.</span><span class="n">task_id</span> <span class="o">=</span> <span class="n">task_id</span>
    <span class="n">task</span><span class="o">.</span><span class="n">add_done_callback</span><span class="p">(</span><span class="n">_put_result</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_put_result</span><span class="p">(</span><span class="n">task</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">exception</span> <span class="o">:=</span> <span class="n">task</span><span class="o">.</span><span class="n">exception</span><span class="p">():</span>
        <span class="n">_result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">task</span><span class="o">.</span><span class="n">task_id</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">exception</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_result_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">task</span><span class="o">.</span><span class="n">task_id</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
</code></pre></div>

<p>back in the result handler,
we find the maching future,
and set its result accordingly:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__handle_results</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">ok</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">outer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ok</span><span class="p">:</span>
                <span class="n">outer</span><span class="o">.</span><span class="n">set_result</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outer</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div>

<p>and it works:</p>
<div class="highlight code-container"><pre class="code" data-lang="Bash Session"><span></span><code><span class="gp">$ </span>python<span class="w"> </span>ptpe.py
<span class="go">doing: 0</span>
<span class="go">doing: 1</span>
<span class="go">doing: 2</span>
<span class="go">[0, 1, 4]</span>
</code></pre></div>
<p>but does it really?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 6.220</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 3.397</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 2.600</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">))</span>
<span class="go">elapsed: 2.664</span>
</code></pre></div>
<p>it does!</p>
<p>8.8s / 2.6s ~= 3.3x
...that's not <em>quite</em> the 4 CPUs my laptop has,
but it's pretty close,
and much better than the 2.3x we got from using processes alone</p>
<h2 id="dead-workers">dead workers<span class="headerlink">&nbsp;<a href="#dead-workers" title="permalink">#</a></span></h2>
<p>The ProcessPoolExecutor documentation keeps talking about broken pools.
I wonder what happens if we kill a worker process.</p>
<p>Since we can aready customize the behavior of <code>benchmark()</code>
via <code>timer</code>, let's do it like that
(a combo of pgrep and pkill would do it as well,
but it gets kinda tedious after the first few times).</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">terminate_children</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">terminate</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
            <span class="n">child</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
    <span class="n">threading</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="n">interval</span><span class="p">,</span> <span class="n">terminate</span><span class="p">)</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="k">yield</span>
</code></pre></div>

<p>First, a baseline:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessPoolExecutor</span><span class="p">(</span><span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">terminate_children</span><span class="p">)</span>
<span class="go">[ one second later ]</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
  File <span class="nb">&quot;concurrent/futures/_base.py&quot;</span>, line <span class="m">317</span>, in <span class="n">_result_or_cancel</span>
<span class="w">    </span><span class="k">return</span> <span class="n">fut</span><span class="o">.</span><span class="n">result</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span>
  File <span class="nb">&quot;concurrent/futures/_base.py&quot;</span>, line <span class="m">456</span>, in <span class="n">result</span>
<span class="w">    </span><span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_result</span><span class="p">()</span>
  File <span class="nb">&quot;concurrent/futures/_base.py&quot;</span>, line <span class="m">401</span>, in <span class="n">__get_result</span>
<span class="w">    </span><span class="k">raise</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exception</span>
<span class="gr">concurrent.futures.process.BrokenProcessPool</span>: <span class="n">A process in the process pool was terminated abruptly while the future was running or pending.</span>
</code></pre></div>
<p>Neat!</p>
<p>What about <em>our</em> executor?</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">terminate_children</span><span class="p">)</span>
<span class="go">[ one second later ]</span>
<span class="go">[ ... ]</span>
<span class="go">[ one eternity later ]</span>
<span class="go">[ ... ]</span>
<span class="go">[ it never ends ]</span>
</code></pre></div>
<p>so, there's actually two scenarios here,
and in either case we want to fail <em>all</em> pending tasks with BrokenProcessPool.</p>
<!-- TODO: quote docs -->
<p>First, if map() is still submitting tasks,
<code>inner</code> will fail with BrokenProcessPool.</p>
<p>As we'll see, we don't need to do any special handling here,
since fixing the second case fixes this one too.
However, we should still propagate <code>inner</code> exceptions to the <code>outer</code> task,
otherwise we may end up shadowing other exceptions.</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">submit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># ...</span>
        <span class="n">inner</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">_submit</span><span class="p">,</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">inner</span><span class="o">.</span><span class="n">task_id</span> <span class="o">=</span> <span class="n">task_id</span>
        <span class="n">inner</span><span class="o">.</span><span class="n">add_done_callback</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__handle_inner</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outer</span>
</code></pre></div>

<p>Of note, we need to expect by the task to have been already
handled by the handling of the second case:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__handle_inner</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inner</span><span class="p">):</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="n">inner</span><span class="o">.</span><span class="n">task_id</span>
        <span class="k">if</span> <span class="n">exception</span> <span class="o">:=</span> <span class="n">inner</span><span class="o">.</span><span class="n">exception</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">outer</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="n">outer</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">exception</span><span class="p">)</span>
</code></pre></div>

<p>This already fixes the case where the worker dies almost instantly:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">timer</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">terminate_children</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">concurrent.futures.process.BrokenProcessPool</span>: <span class="n">A process in the process pool was terminated abruptly while the future was running or pending.</span>
</code></pre></div>
<p>Second, if map() already finished submitting tasks,
it'll wait forever for results that will never come.</p>
<p>We need to somehow check regularly if the executor is broken – but how?
Technically <code>ProcessPoolExecutor._broken</code> exists,
but we don't want to depend on internals.
Alterntively, we can try submitting a dummy task ourselves:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python"><span></span><code>    <span class="k">def</span><span class="w"> </span><span class="nf">__handle_results</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__result_queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mf">.1</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">cancel</span><span class="p">()</span>
                <span class="k">except</span> <span class="n">concurrent</span><span class="o">.</span><span class="n">futures</span><span class="o">.</span><span class="n">BrokenExecutor</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">exc</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
                    <span class="k">break</span>
                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="s1">&#39;shutdown&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span> <span class="n">e</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">value</span><span class="p">:</span>
                <span class="k">return</span>

            <span class="n">task_id</span><span class="p">,</span> <span class="n">ok</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">if</span> <span class="n">outer</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">ok</span><span class="p">:</span>
                    <span class="n">outer</span><span class="o">.</span><span class="n">set_result</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">outer</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">outer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tasks</span><span class="o">.</span><span class="n">popitem</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">outer</span><span class="o">.</span><span class="n">set_exception</span><span class="p">(</span><span class="n">exc</span><span class="p">)</span>
</code></pre></div>

<p>We take advantage of the Queue.get() timeout feature
to only submit the dummy task if we're not receiving results.
When the executor is broken, submit() raises BrokenExecutor,
which breaks us out of the while true loop
so we can fail the pending tasks.
Like so:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ProcessThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_client</span><span class="p">),</span> <span class="n">timer</span><span class="o">=</span><span class="n">terminate_children</span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">concurrent.futures.process.BrokenProcessPool</span>: <span class="n">A child process terminated abruptly, the process pool is not usable anymore</span>
</code></pre></div>
<hr />
<p>So, yeah, I think we're done.
Here's the final <a class="attachment" href="/_file/ptpe/ptpe.py">executor</a> and <a class="attachment" href="/_file/ptpe/bench.py">benchmark</a> code.</p>
<p>Some features that are left as an exercise for the reader:</p>
<ul>
<li>allow providing an initialized for the ThreadPoolExecutor as well</li>
<li>allow selecting the mutliprocessing context</li>
<li>support <code>shutdown(cancel_futures=True)</code></li>
</ul>
<h2 id="bonus-free-threading">Bonus: free threading<span class="headerlink">&nbsp;<a href="#bonus-free-threading" title="permalink">#</a></span></h2>
<p>So, a lot of people have been very excited
for the experimental free threading support added to Python 3.13,
and for good reasons; behold:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="go">$ python3.13t</span>
<span class="go">Python 3.13.2 experimental free-threading build</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">bench</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init_client</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">30</span><span class="p">))</span>
<span class="go">elapsed: 8.224</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">40</span><span class="p">))</span>
<span class="go">elapsed: 6.193</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmark</span><span class="p">(</span><span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="mi">120</span><span class="p">))</span>
<span class="go">elapsed: 2.323</span>
</code></pre></div>
<p>Even better than the best ProcessThreadPoolExecutor time,
without any of the fuss!</p>
<p>Alas, I had to comment out the bits that used psutil, since:</p>
<div class="highlight code-container"><pre class="code" data-lang="Python console session"><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">psutil</span>
<span class="go">zsh: segmentation fault  python3.13t</span>
</code></pre></div>
<p>[ soon cat here ]</p>
<p>Soon.™</p>
<section class="footnotes">
<ol>
<li id="fn-1"><p>The psutil documentation for <a class="external" href="https://psutil.readthedocs.io/en/latest/#psutil.Process.memory_full_info">memory_full_info()</a>
explains the difference quite nicely and links to further resources,
because <a class="internal" href="/output#good-libraries-educate">good libraries educate</a>. <a href="#fnref-1" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-2"><p>note that on macOS I had to run Python with sudo
to be able to get USS for child processes <a href="#fnref-2" class="footnote"><sup>[return]</sup></a></p></li>
<li id="fn-3"><p>https://github.com/nilp0inter/threadedprocess <a href="#fnref-3" class="footnote"><sup>[return]</sup></a></p></li>
</ol>
</section>








</div>
</main>


<footer class="footer">
<p class="text-gray">
<a href="/">home</a>
∙ <a href="/_feed/index.xml">feed</a>
∙ <a href="/about">about</a>

∙ © 2021 lemon24



</footer>


</div>